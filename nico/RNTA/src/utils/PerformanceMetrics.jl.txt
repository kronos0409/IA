module PerformanceMetrics

export track_performance, log_metrics, compute_statistics
export MetricsTracker, MetricsLogger, benchmark_model
export memory_profile, latency_profile, throughput_test
export create_performance_report, compare_configurations
export TensorMetrics, ModelMetrics, TrainingMetrics

using Statistics
using Dates
using CUDA
using LinearAlgebra
using Printf

using ..RNTA: SpatialField, BrainSpace

"""
    MetricsTracker

Sistema para rastrear métricas de rendimiento del modelo.
"""
mutable struct MetricsTracker
    # Métricas de memoria
    memory_usage::Dict{Symbol,Vector{Float64}}
    peak_memory::Dict{Symbol,Float64}
    
    # Métricas de tiempo
    operation_timings::Dict{Symbol,Vector{Float64}}
    epoch_times::Vector{Float64}
    
    # Métricas de modelo
    loss_values::Vector{Float64}
    accuracy_values::Vector{Union{Nothing,Float64}}
    
    # Métricas de rendimiento computacional
    throughput::Vector{Float64}  # elementos/segundo
    flops_utilization::Vector{Float64}  # % de pico teórico
    
    # Tiempos de inicio para medición
    timing_starts::Dict{Symbol,Float64}
    
    # Metadatos
    metadata::Dict{Symbol,Any}
    
    # Constructor con valores iniciales
    function MetricsTracker()
        new(
            Dict{Symbol,Vector{Float64}}(),  # memory_usage
            Dict{Symbol,Float64}(),          # peak_memory
            Dict{Symbol,Vector{Float64}}(),  # operation_timings
            Float64[],                       # epoch_times
            Float64[],                       # loss_values
            Union{Nothing,Float64}[],        # accuracy_values
            Float64[],                       # throughput
            Float64[],                       # flops_utilization
            Dict{Symbol,Float64}(),          # timing_starts
            Dict{Symbol,Any}()               # metadata
        )
    end
end

"""
    MetricsLogger

Sistema para registro y persistencia de métricas.
"""
struct MetricsLogger
    log_dir::String
    log_file::Union{Nothing,IOStream}
    metrics_history::Dict{Symbol,Vector{Any}}
    log_level::Symbol  # :detailed, :normal, :minimal
    
    function MetricsLogger(log_dir::String; log_level::Symbol=:normal)
        # Crear directorio si no existe
        if !isdir(log_dir)
            mkpath(log_dir)
        end
        
        # Preparar archivo de log
        log_file_path = joinpath(log_dir, "metrics_$(Dates.format(now(), "yyyymmdd_HHMMSS")).log")
        log_file = open(log_file_path, "w")
        
        new(
            log_dir,
            log_file,
            Dict{Symbol,Vector{Any}}(),
            log_level
        )
    end
end

"""
    TensorMetrics

Métricas específicas para operaciones tensoriales.
"""
struct TensorMetrics
    # Dimensiones y propiedades estructurales
    dimensions::Tuple{Int,Int,Int}
    total_elements::Int
    memory_size_bytes::Int
    
    # Propiedades estadísticas
    sparsity::Float64  # proporción de elementos cercanos a cero
    mean_value::Float64
    std_value::Float64
    min_value::Float64
    max_value::Float64
    
    # Propiedades computacionales
    computational_density::Float64  # operaciones por byte
    gradient_norm::Union{Nothing,Float64}
    
    # Constructor con valores calculados a partir de un campo tensorial
    function TensorMetrics(field::SpatialField; with_gradients::Bool=false)
        # Calcular propiedades básicas
        dims = size(field.data)
        total_elems = length(field.data)
        mem_size = total_elems * sizeof(eltype(field.data))
        
        # Calcular propiedades estadísticas
        data_array = Array(field.data)  # Asegurar que tenemos un Array (por si es CuArray)
        
        sparsity_threshold = 1e-6
        sparsity = count(abs.(data_array) .< sparsity_threshold) / total_elems
        
        mean_val = mean(data_array)
        std_val = std(data_array)
        min_val = minimum(data_array)
        max_val = maximum(data_array)
        
        # Densidad computacional (aproximación simplificada)
        # Basado en la idea de que elementos no cercanos a cero requieren cómputo
        comp_density = (1 - sparsity) * 2  # ~2 operaciones por elemento no cero
        
        # Norma del gradiente (si está disponible)
        grad_norm = nothing
        if with_gradients && haskey(field.metadata, "gradients")
            grad_data = field.metadata["gradients"]
            grad_norm = norm(grad_data)
        end
        
        new(
            dims,
            total_elems,
            mem_size,
            sparsity,
            mean_val,
            std_val,
            min_val,
            max_val,
            comp_density,
            grad_norm
        )
    end
end

"""
    ModelMetrics

Métricas a nivel de modelo completo.
"""
struct ModelMetrics
    # Tamaño y complejidad
    total_parameters::Int
    total_fields::Int
    total_connections::Int
    model_size_bytes::Int
    
    # Métricas computacionales
    peak_memory_usage::Dict{Symbol,Float64}  # Por dispositivo
    avg_memory_usage::Dict{Symbol,Float64}
    estimated_flops::Float64
    
    # Métricas de rendimiento
    inference_latency_ms::Float64
    forward_pass_ms::Float64
    backward_pass_ms::Float64
    
    # Eficiencia
    memory_efficiency::Float64  # ratio de memoria útil/total
    compute_efficiency::Float64  # ratio de cómputo útil/total
end

"""
    TrainingMetrics

Métricas relacionadas con el entrenamiento.
"""
struct TrainingMetrics
    # Información básica
    dataset_size::Int
    batch_size::Int
    learning_rate::Float64
    
    # Progreso de entrenamiento
    current_epoch::Int
    total_epochs::Int
    samples_processed::Int
    
    # Métricas de calidad
    train_loss::Float64
    validation_loss::Union{Nothing,Float64}
    train_accuracy::Union{Nothing,Float64}
    validation_accuracy::Union{Nothing,Float64}
    
    # Métricas de tiempo
    epoch_time_seconds::Float64
    samples_per_second::Float64
    time_breakdown::Dict{Symbol,Float64}  # %tiempo en data_loading, forward, backward, optimization
    
    # Métricas de gradiente
    gradient_norm::Float64
    gradient_noise_scale::Union{Nothing,Float64}
end

"""
    track_performance(tracker::MetricsTracker, key::Symbol, value::Number)

Registra una métrica de rendimiento específica.
"""
function track_performance(tracker::MetricsTracker, key::Symbol, value::Number)
    # Inicializar vector para la clave si no existe
    if key ∉ keys(tracker.memory_usage) && key ∉ keys(tracker.operation_timings)
        if startswith(String(key), "mem_")
            tracker.memory_usage[key] = Float64[]
        else
            tracker.operation_timings[key] = Float64[]
        end
    end
    
    # Registrar el valor en el vector apropiado
    if startswith(String(key), "mem_")
        push!(tracker.memory_usage[key], Float64(value))
        
        # Actualizar pico de memoria
        if get(tracker.peak_memory, key, 0.0) < value
            tracker.peak_memory[key] = Float64(value)
        end
    else
        push!(tracker.operation_timings[key], Float64(value))
    end
end

"""
    start_timing(tracker::MetricsTracker, key::Symbol)

Inicia la medición de tiempo para una operación específica.
"""
function start_timing(tracker::MetricsTracker, key::Symbol)
    tracker.timing_starts[key] = time()
end

"""
    end_timing(tracker::MetricsTracker, key::Symbol)

Finaliza la medición de tiempo para una operación específica y registra el resultado.
"""
function end_timing(tracker::MetricsTracker, key::Symbol)
    if key ∉ keys(tracker.timing_starts)
        error("No se encontró un inicio de tiempo para la clave: $key")
    end
    
    elapsed = time() - tracker.timing_starts[key]
    track_performance(tracker, key, elapsed)
    delete!(tracker.timing_starts, key)
    
    return elapsed
end

"""
    track_loss(tracker::MetricsTracker, loss_value::Number)

Registra un valor de pérdida durante el entrenamiento.
"""
function track_loss(tracker::MetricsTracker, loss_value::Number)
    push!(tracker.loss_values, Float64(loss_value))
end

"""
    track_accuracy(tracker::MetricsTracker, accuracy::Union{Nothing,Number})

Registra un valor de precisión durante el entrenamiento.
"""
function track_accuracy(tracker::MetricsTracker, accuracy::Union{Nothing,Number})
    push!(tracker.accuracy_values, accuracy === nothing ? nothing : Float64(accuracy))
end

"""
    track_epoch_time(tracker::MetricsTracker, seconds::Number)

Registra el tiempo de procesamiento de una época.
"""
function track_epoch_time(tracker::MetricsTracker, seconds::Number)
    push!(tracker.epoch_times, Float64(seconds))
end

"""
    compute_statistics(values::Vector{<:Number})

Calcula estadísticas descriptivas para un conjunto de valores.
"""
function compute_statistics(values::Vector{<:Number})
    if isempty(values)
        return Dict(
            :count => 0,
            :mean => NaN,
            :std => NaN,
            :min => NaN,
            :max => NaN,
            :median => NaN
        )
    end
    
    return Dict(
        :count => length(values),
        :mean => mean(values),
        :std => std(values),
        :min => minimum(values),
        :max => maximum(values),
        :median => median(values)
    )
end

"""
    create_performance_report(tracker::MetricsTracker)

Genera un informe completo de rendimiento a partir de las métricas registradas.
"""
function create_performance_report(tracker::MetricsTracker)
    report = Dict{Symbol,Any}()
    
    # Estadísticas de memoria
    memory_stats = Dict{Symbol,Any}()
    for (key, values) in tracker.memory_usage
        memory_stats[key] = compute_statistics(values)
    end
    memory_stats[:peak] = tracker.peak_memory
    report[:memory] = memory_stats
    
    # Estadísticas de tiempo
    timing_stats = Dict{Symbol,Any}()
    for (key, values) in tracker.operation_timings
        timing_stats[key] = compute_statistics(values)
    end
    report[:timing] = timing_stats
    
    # Estadísticas de entrenamiento
    if !isempty(tracker.loss_values)
        report[:training] = Dict(
            :loss => compute_statistics(tracker.loss_values),
            :epoch_time => compute_statistics(tracker.epoch_times)
        )
        
        # Incluir precisión si está disponible
        valid_accuracy = filter(x -> x !== nothing, tracker.accuracy_values)
        if !isempty(valid_accuracy)
            report[:training][:accuracy] = compute_statistics(valid_accuracy)
        end
    end
    
    # Métricas de rendimiento computacional
    if !isempty(tracker.throughput)
        report[:performance] = Dict(
            :throughput => compute_statistics(tracker.throughput),
            :flops_utilization => compute_statistics(tracker.flops_utilization)
        )
    end
    
    # Incluir cualquier metadato
    report[:metadata] = tracker.metadata
    
    return report
end

"""
    log_metrics(logger::MetricsLogger, metrics::Dict)

Registra métricas en el archivo de log y en el historial.
"""
function log_metrics(logger::MetricsLogger, metrics::Dict)
    timestamp = Dates.format(now(), "yyyy-mm-dd HH:MM:SS")
    
    # Formatear para el archivo de log
    log_line = "$timestamp - "
    
    # Determinar qué métricas registrar según el nivel
    metrics_to_log = if logger.log_level == :detailed
        metrics  # Todas las métricas
    elseif logger.log_level == :minimal
        # Solo métricas clave
        filter(pair -> pair.first in [:loss, :accuracy, :epoch, :samples_per_second], metrics)
    else  # :normal
        # Métricas importantes
        filter(pair -> !(pair.first in [:detailed_timings, :memory_usage]), metrics)
    end
    
    # Formatear métricas para log
    for (key, value) in metrics_to_log
        if value isa Number
            log_line *= "$(key)=$(round(value, digits=5)) "
        else
            log_line *= "$(key)=$(value) "
        end
    end
    
    # Escribir al archivo
    println(logger.log_file, log_line)
    flush(logger.log_file)
    
    # Guardar en el historial
    for (key, value) in metrics
        if !haskey(logger.metrics_history, key)
            logger.metrics_history[key] = []
        end
        push!(logger.metrics_history[key], value)
    end
end

"""
    benchmark_model(brain_space::BrainSpace, input_dims::Tuple, num_iterations::Int=100;
                   warmup::Int=10, use_cuda::Bool=CUDA.functional())

Realiza un benchmark exhaustivo del modelo.
"""
function benchmark_model(brain_space::BrainSpace, input_dims::Tuple, num_iterations::Int=100;
                       warmup::Int=10, use_cuda::Bool=CUDA.functional())
    
    tracker = MetricsTracker()
    
    # Preparar datos de entrada
    input_data = randn(Float32, input_dims)
    if use_cuda
        input_data = CuArray(input_data)
    end
    
    # Iteraciones de calentamiento
    for i in 1:warmup
        # Ejecución del modelo (en una implementación real, esto llamaría al modelo)
        # forward_pass(brain_space, input_data)
    end
    
    # Sincronizar dispositivo si es CUDA
    if use_cuda
        CUDA.synchronize()
    end
    
    # Medir latencia de inferencia
    latencies = zeros(num_iterations)
    
    for i in 1:num_iterations
        # Iniciar tiempo
        start_time = time()
        
        # Ejecución del modelo
        # forward_pass(brain_space, input_data)
        
        # Sincronizar y medir tiempo
        if use_cuda
            CUDA.synchronize()
        end
        latencies[i] = (time() - start_time) * 1000  # Convertir a ms
        
        # Recopilar uso de memoria
        if use_cuda
            free_mem, total_mem = CUDA.MemoryInfo()
            used_mem = total_mem - free_mem
            track_performance(tracker, :mem_gpu, used_mem / 1024^2)  # MB
        end
        
        track_performance(tracker, :mem_cpu, Sys.free_memory() / 1024^2)  # MB
    end
    
    # Calcular estadísticas
    stats = compute_statistics(latencies)
    
    # Estimar FLOPS
    estimated_flops = estimate_model_flops(brain_space, input_dims)
    avg_time_seconds = stats[:mean] / 1000
    estimated_tflops = estimated_flops / 1e12 / avg_time_seconds
    
    # Registrar en tracker
    tracker.metadata[:estimated_flops] = estimated_flops
    tracker.metadata[:tflops] = estimated_tflops
    tracker.metadata[:batch_size] = input_dims[1]
    tracker.metadata[:input_dims] = input_dims
    tracker.metadata[:hardware] = use_cuda ? "CUDA" : "CPU"
    
    if use_cuda
        device_props = CUDA.device_properties()
        tracker.metadata[:gpu_name] = device_props.name
        tracker.metadata[:compute_capability] = "$(device_props.capability.major).$(device_props.capability.minor)"
    else
        tracker.metadata[:cpu_info] = Dict(
            :cores => Sys.CPU_CORES,
            :threads => Sys.CPU_THREADS
        )
    end
    
    # Retornar resultados
    return Dict(
        :latency_ms => stats,
        :throughput => input_dims[1] / (stats[:mean] / 1000),  # elementos por segundo
        :estimated_tflops => estimated_tflops,
        :memory_usage => Dict(
            :peak_gpu_mb => get(tracker.peak_memory, :mem_gpu, 0.0),
            :peak_cpu_mb => get(tracker.peak_memory, :mem_cpu, 0.0)
        ),
        :tracker => tracker
    )
end

"""
    estimate_model_flops(brain_space::BrainSpace, input_dims::Tuple)

Estima el número de operaciones de punto flotante (FLOPS) para un pase del modelo.
"""
function estimate_model_flops(brain_space::BrainSpace, input_dims::Tuple)
    # Implementación conceptual
    # En un caso real, esto requeriría analizar la estructura del modelo
    
    # Contar campos y conexiones
    num_fields = length(brain_space.fields)
    num_connections = length(brain_space.connections)
    
    # Estimar operaciones por campo (activaciones, normalizaciones, etc.)
    flops_per_field = 10_000_000  # Ejemplo: 10M ops por campo
    
    # Estimar operaciones por conexión (multiplicaciones, sumas, etc.)
    flops_per_connection = 100_000_000  # Ejemplo: 100M ops por conexión
    
    # Ajustar por tamaño de batch
    batch_size = input_dims[1]
    
    total_flops = (num_fields * flops_per_field + num_connections * flops_per_connection) * batch_size
    
    return total_flops
end

"""
    memory_profile(brain_space::BrainSpace, input_dims::Tuple;
                  track_detailed::Bool=false, use_cuda::Bool=CUDA.functional())

Analiza el uso de memoria del modelo durante la ejecución.
"""
function memory_profile(brain_space::BrainSpace, input_dims::Tuple;
                       track_detailed::Bool=false, use_cuda::Bool=CUDA.functional())
    
    # Inicializar seguimiento
    baseline_memory = Dict{Symbol,Float64}()
    peak_memory = Dict{Symbol,Float64}()
    
    # Medir línea base de memoria
    if use_cuda
        CUDA.reclaim()
        GC.gc()
        free_mem, total_mem = CUDA.MemoryInfo()
        baseline_memory[:gpu] = (total_mem - free_mem) / 1024^2  # MB
    end
    
    GC.gc()
    baseline_memory[:cpu] = (Sys.total_memory() - Sys.free_memory()) / 1024^2  # MB
    
    # Preparar datos de entrada
    input_data = randn(Float32, input_dims)
    if use_cuda
        input_data = CuArray(input_data)
    end
    
    # Lista de puntos de medición
    measurement_points = [:initialization, :forward_pass, :computation_complete]
    memory_usage = Dict{Symbol,Dict{Symbol,Float64}}()
    
    # Medir uso de memoria en puntos clave
    for point in measurement_points
        # En una implementación real, aquí iría el código que ejecuta cada fase
        
        # Sincronizar si es CUDA
        if use_cuda
            CUDA.synchronize()
        end
        
        # Medir memoria
        current_memory = Dict{Symbol,Float64}()
        
        if use_cuda
            free_mem, total_mem = CUDA.MemoryInfo()
            current_memory[:gpu] = (total_mem - free_mem) / 1024^2  # MB
            peak_memory[:gpu] = get(peak_memory, :gpu, 0.0) < current_memory[:gpu] ? 
                              current_memory[:gpu] : get(peak_memory, :gpu, 0.0)
        end
        
        current_memory[:cpu] = (Sys.total_memory() - Sys.free_memory()) / 1024^2  # MB
        peak_memory[:cpu] = get(peak_memory, :cpu, 0.0) < current_memory[:cpu] ? 
                          current_memory[:cpu] : get(peak_memory, :cpu, 0.0)
        
        memory_usage[point] = current_memory
    end
    
    # Calcular memoria utilizada (delta desde la línea base)
    memory_delta = Dict{Symbol,Dict{Symbol,Float64}}()
    for (point, usage) in memory_usage
        memory_delta[point] = Dict{Symbol,Float64}()
        for (device, value) in usage
            memory_delta[point][device] = value - baseline_memory[device]
        end
    end
    
    # Detalle por componente si se solicita
    component_memory = Dict{Symbol,Float64}()
    if track_detailed
        # En una implementación real, esto recorrería la estructura del modelo
        # y estimaría la memoria utilizada por cada componente
        
        # Ejemplo:
        for field in brain_space.fields
            # Estimar memoria del campo
            field_memory = estimate_field_memory(field)
            component_memory[Symbol("field_$(field.metadata[:id])")] = field_memory
        end
        
        for connection in brain_space.connections
            # Estimar memoria de la conexión
            connection_memory = estimate_connection_memory(connection)
            component_memory[Symbol("connection_$(connection.metadata[:id])")] = connection_memory
        end
    end
    
    return Dict(
        :baseline => baseline_memory,
        :usage => memory_usage,
        :delta => memory_delta,
        :peak => peak_memory,
        :by_component => component_memory
    )
end

"""
    estimate_field_memory(field::SpatialField)

Estima el uso de memoria de un campo.
"""
function estimate_field_memory(field::SpatialField)
    # Memoria del tensor principal
    tensor_bytes = length(field.data) * sizeof(eltype(field.data))
    
    # Memoria adicional (metadatos, gradientes si hay, etc.)
    metadata_bytes = 1000  # Estimación simplificada
    
    # Gradientes si están presentes
    gradient_bytes = 0
    if haskey(field.metadata, "gradients")
        gradient_bytes = length(field.metadata["gradients"]) * sizeof(eltype(field.metadata["gradients"]))
    end
    
    total_bytes = tensor_bytes + metadata_bytes + gradient_bytes
    return total_bytes / 1024^2  # Convertir a MB
end

"""
    estimate_connection_memory(connection)

Estima el uso de memoria de una conexión.
"""
function estimate_connection_memory(connection)
    # En una implementación real, esto analizaría la estructura de la conexión
    
    # Estimación simplificada basada en tamaño de pesos
    if haskey(connection.metadata, "weights")
        weights = connection.metadata["weights"]
        weights_bytes = length(weights) * sizeof(eltype(weights))
        
        # Memoria adicional para gradientes, optimizador, etc.
        additional_bytes = weights_bytes * 3  # Aproximadamente 3x para gradientes, momentos, etc.
        
        return (weights_bytes + additional_bytes) / 1024^2  # Convertir a MB
    else
        # Estimación predeterminada si no hay información de pesos
        return 10.0  # 10 MB por defecto
    end
end

"""
    latency_profile(brain_space::BrainSpace, input_dims::Tuple, num_iterations::Int=10;
                   breakdown::Bool=true, use_cuda::Bool=CUDA.functional())

Analiza la latencia del modelo con desglose por componentes.
"""
function latency_profile(brain_space::BrainSpace, input_dims::Tuple, num_iterations::Int=10;
                        breakdown::Bool=true, use_cuda::Bool=CUDA.functional())
    
    # Preparar datos
    input_data = randn(Float32, input_dims)
    if use_cuda
        input_data = CuArray(input_data)
    end
    
    # Iteraciones de calentamiento
    for i in 1:3
        # forward_pass(brain_space, input_data)
    end
    
    # Sincronizar
    if use_cuda
        CUDA.synchronize()
    end
    
    # Medir latencia general
    total_latencies = zeros(num_iterations)
    
    for i in 1:num_iterations
        start_time = time()
        
        # forward_pass(brain_space, input_data)
        
        if use_cuda
            CUDA.synchronize()
        end
        total_latencies[i] = (time() - start_time) * 1000  # Convertir a ms
    end
    
    results = Dict(
        :total_latency_ms => compute_statistics(total_latencies)
    )
    
    # Desglose por componentes si se solicita
    if breakdown
        component_latencies = Dict{Symbol,Vector{Float64}}()
        
        # Medir latencia por componente
        for i in 1:num_iterations
            # En una implementación real, esto mediría el tiempo de ejecución
            # de cada componente principal del modelo
            
            # Ejemplo:
            # start_time = time()
            # process_input_layer(brain_space, input_data)
            # component_latencies[:input_layer] = get(component_latencies, :input_layer, Float64[])
            # push!(component_latencies[:input_layer], (time() - start_time) * 1000)
            
            # start_time = time()
            # process_main_layers(brain_space, input_data)
            # component_latencies[:main_layers] = get(component_latencies, :main_layers, Float64[])
            # push!(component_latencies[:main_layers], (time() - start_time) * 1000)
            
            # start_time = time()
            # process_output_layer(brain_space, input_data)
            # component_latencies[:output_layer] = get(component_latencies, :output_layer, Float64[])
            # push!(component_latencies[:output_layer], (time() - start_time) * 1000)
            
            # Ejemplo simulado para cortical layers
            component_latencies[:cortical_layers] = get(component_latencies, :cortical_layers, Float64[])
            push!(component_latencies[:cortical_layers], rand(1.0:5.0))
            
            # Ejemplo simulado para attention system
            component_latencies[:attention_system] = get(component_latencies, :attention_system, Float64[])
            push!(component_latencies[:attention_system], rand(2.0:7.0))
            
            # Ejemplo simulado para prefrontal system
            component_latencies[:prefrontal_system] = get(component_latencies, :prefrontal_system, Float64[])
            push!(component_latencies[:prefrontal_system], rand(3.0:8.0))
        end
        
        # Calcular estadísticas por componente
        component_stats = Dict{Symbol,Dict{Symbol,Any}}()
        for (component, latencies) in component_latencies
            component_stats[component] = compute_statistics(latencies)
        end
        
        results[:component_latency_ms] = component_stats
        
        # Calcular porcentaje del tiempo total
        total_avg = results[:total_latency_ms][:mean]
        component_percentages = Dict{Symbol,Float64}()
        
        for (component, stats) in component_stats
            component_percentages[component] = (stats[:mean] / total_avg) * 100
        end
        
        results[:component_percentage] = component_percentages
    end
    
    return results
end

"""
    throughput_test(brain_space::BrainSpace, batch_sizes::Vector{Int}, 
                  sequence_length::Int, num_iterations::Int=5;
                  use_cuda::Bool=CUDA.functional())

Mide el rendimiento del modelo con diferentes tamaños de batch.
"""
function throughput_test(brain_space::BrainSpace, batch_sizes::Vector{Int}, 
                       sequence_length::Int, num_iterations::Int=5;
                       use_cuda::Bool=CUDA.functional())
    
    results = Dict{Int,Dict{Symbol,Any}}()
    
    for batch_size in batch_sizes
        input_dims = (batch_size, sequence_length, 64)  # Ejemplo de dimensiones
        
        # Preparar datos
        input_data = randn(Float32, input_dims)
        if use_cuda
            input_data = CuArray(input_data)
        end
        
        # Calentar
        for i in 1:2
            # forward_pass(brain_space, input_data)
        end
        
        if use_cuda
            CUDA.synchronize()
        end
        
        # Medir
        batch_times = zeros(num_iterations)
        
        for i in 1:num_iterations
            start_time = time()
            
            # forward_pass(brain_space, input_data)
            
            if use_cuda
                CUDA.synchronize()
            end
            
            batch_times[i] = time() - start_time
        end
        
        # Calcular throughput
        avg_time = mean(batch_times)
        tokens_per_second = batch_size * sequence_length / avg_time
        samples_per_second = batch_size / avg_time
        
        # Registrar resultados
        results[batch_size] = Dict(
            :avg_time_seconds => avg_time,
            :tokens_per_second => tokens_per_second,
            :samples_per_second => samples_per_second,
            :times => batch_times
        )
    end
    
    # Determinar batch óptimo (mayor throughput)
    optimal_batch = maximum([(bs, results[bs][:samples_per_second]) for bs in batch_sizes], 
                           by=x->x[2])
    
    return Dict(
        :by_batch_size => results,
        :optimal_batch => optimal_batch[1],
        :max_throughput => optimal_batch[2]
    )
end

"""
    compare_configurations(configs::Vector{Dict}, brain_space::BrainSpace, 
                         input_dims::Tuple, num_iterations::Int=10)

Compara múltiples configuraciones del modelo para rendimiento.
"""
function compare_configurations(configs::Vector{Dict}, brain_space::BrainSpace, 
                              input_dims::Tuple, num_iterations::Int=10)
    
    results = Dict{String,Dict{Symbol,Any}}()
    
    for (i, config) in enumerate(configs)
        config_name = get(config, :name, "config_$i")
        
        # Aplicar configuración
        # En una implementación real, esto modificaría el modelo según la configuración
        # configured_model = apply_configuration(brain_space, config)
        configured_model = brain_space  # Placeholder
        
        # Preparar datos
        use_cuda = get(config, :use_cuda, CUDA.functional())
        input_data = randn(Float32, input_dims)
        if use_cuda
            input_data = CuArray(input_data)
        end
        
        # Calentar
        for i in 1:3
            # forward_pass(configured_model, input_data)
        end
        
        if use_cuda
            CUDA.synchronize()
        end
        
        # Medir rendimiento
        latencies = zeros(num_iterations)
        memory_usage = zeros(num_iterations)
        
        for i in 1:num_iterations
            # Limpiar memoria antes de cada iteración
            if use_cuda
                CUDA.reclaim()
            end
            GC.gc()
            
            # Medir latencia
            start_time = time()
            # forward_pass(configured_model, input_data)
            
            if use_cuda
                CUDA.synchronize()
            end
            latencies[i] = (time() - start_time) * 1000  # ms
            
            # Medir memoria
            if use_cuda
                free_mem, total_mem = CUDA.MemoryInfo()
                memory_usage[i] = (total_mem - free_mem) / 1024^2  # MB
            else
                memory_usage[i] = (Sys.total_memory() - Sys.free_memory()) / 1024^2  # MB
            end
        end
        
        # Calcular métricas
        results[config_name] = Dict(
            :latency_ms => compute_statistics(latencies),
            :memory_mb => compute_statistics(memory_usage),
            :throughput => input_dims[1] / (mean(latencies) / 1000),
            :config => config
        )
    end
    
    # Determinar mejor configuración (menor latencia)
    best_config = minimum([(name, results[name][:latency_ms][:mean]) for name in keys(results)], 
                         by=x->x[2])
    
    return Dict(
        :by_config => results,
        :best_config => best_config[1],
        :best_latency => best_config[2]
    )
end

end # module